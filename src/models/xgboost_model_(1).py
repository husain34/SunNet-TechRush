# -*- coding: utf-8 -*-
"""xgboost_model (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19K17MMVLzYDSDi5G9Rv_Xr8YqzVwiOA_
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import joblib
import seaborn as sns

df = pd.read_csv('../data/solarpowergeneration.csv')

target = 'power-generated'
features = [col for col in df.columns if col != target]

X = df[features]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

model = xgb.XGBRegressor(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    gamma=0.1,
    random_state=42
)

model.fit(X_train, y_train)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")

plt.figure(figsize=(10, 4))
plt.plot(y_test.values, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.legend()
plt.title("XGBoost: Predicted vs Actual Solar Power Generation")
plt.grid(True)
plt.show()

residuals = y_test.values - y_pred

plt.figure(figsize=(10, 3))
plt.plot(residuals, color='orange')
plt.axhline(0, color='black', linestyle='--')
plt.title("Residuals (Actual - Predicted)")
plt.xlabel("Sample Index")
plt.ylabel("Error")
plt.grid(True)
plt.tight_layout()
plt.show()

sns.histplot(residuals, kde=True, color='green')
plt.title("Distribution of Residuals")
plt.xlabel("Prediction Error")
plt.ylabel("Frequency")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred, alpha=0.4, color='navy')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.title("Actual vs Predicted (XGBoost)")
plt.xlabel("Actual Power")
plt.ylabel("Predicted Power")
plt.grid(True)
plt.tight_layout()
plt.show()

importances = model.feature_importances_
feature_names = X.columns

plt.figure(figsize=(10, 4))
sns.barplot(x=importances, y=feature_names, color='skyblue')
plt.title("XGBoost Feature Importances")
plt.xlabel("Importance Score")
plt.tight_layout()
plt.show()

r2 = r2_score(y_test, y_pred)

print("üîç Model Performance Summary")
print(f"üìà MAE  (Mean Absolute Error): {mae:.2f}")
print(f"üìâ RMSE (Root Mean Squared Error): {rmse:.2f}")
print(f"üéØ R¬≤ Score: {r2:.4f}")
print(f"‚úÖ Accuracy-like Score: {r2 * 100:.2f}%")



